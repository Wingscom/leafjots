---
phase: 12-management-dashboard-comprehensive-analytics
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/cryptotax/db/repos/analytics_repo.py
  - src/cryptotax/db/repos/tax_analytics_repo.py
  - src/cryptotax/db/models/taxable_transfer.py
  - src/cryptotax/db/models/__init__.py
  - src/cryptotax/accounting/tax_engine.py
autonomous: true
requirements:
  - ANAL-01
  - ANAL-02
  - ANAL-03

must_haves:
  truths:
    - "AnalyticsRepo can query cash flow, KPI summary, top symbols, composition, and activity data from journal tables"
    - "TaxAnalyticsRepo can query realized gains series, holding distribution, winners/losers, and tax breakdown from capital gains tables"
    - "TaxableTransferRecord table exists in the database and TaxEngine persists taxable transfers during calculation"
  artifacts:
    - path: "src/cryptotax/db/repos/analytics_repo.py"
      provides: "AnalyticsRepo with 11 query methods"
      contains: "class AnalyticsRepo"
    - path: "src/cryptotax/db/repos/tax_analytics_repo.py"
      provides: "TaxAnalyticsRepo with 8 query methods"
      contains: "class TaxAnalyticsRepo"
    - path: "src/cryptotax/db/models/taxable_transfer.py"
      provides: "TaxableTransferRecord SQLAlchemy model"
      contains: "class TaxableTransferRecord"
  key_links:
    - from: "src/cryptotax/db/repos/analytics_repo.py"
      to: "journal_entries + journal_splits + accounts + wallets"
      via: "SQLAlchemy async queries with joins"
      pattern: "select.*JournalEntry.*JournalSplit.*Account.*Wallet"
    - from: "src/cryptotax/accounting/tax_engine.py"
      to: "src/cryptotax/db/models/taxable_transfer.py"
      via: "persist TaxableTransferRecord in _persist_results"
      pattern: "TaxableTransferRecord"
---

<objective>
Create the backend analytics foundation: two new repository classes with comprehensive SQL queries for analytics data, a new TaxableTransferRecord persistence table, and update TaxEngine to persist taxable transfers.

Purpose: All analytics API endpoints and frontend charts depend on these repositories being able to query aggregated data from existing journal/account/capital-gains tables. TaxableTransfer persistence is needed for tax analytics queries.

Output: analytics_repo.py (11 methods), tax_analytics_repo.py (8 methods), taxable_transfer.py model, updated tax_engine.py
</objective>

<execution_context>
@C:/Users/PC/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/PC/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/cryptotax/db/repos/journal_repo.py
@src/cryptotax/db/repos/account_repo.py
@src/cryptotax/db/models/journal.py
@src/cryptotax/db/models/account.py
@src/cryptotax/db/models/capital_gains.py
@src/cryptotax/db/models/wallet.py
@src/cryptotax/accounting/tax_engine.py
@src/cryptotax/db/session.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AnalyticsRepo with 11 query methods</name>
  <files>src/cryptotax/db/repos/analytics_repo.py</files>
  <action>
Create `AnalyticsRepo` class that accepts `AsyncSession` in __init__ (same pattern as JournalRepo).

All methods accept a common filter dataclass or kwargs:
```python
entity_id: uuid.UUID           # required
date_from: datetime | None = None
date_to: datetime | None = None
wallet_id: uuid.UUID | None = None
chain: str | None = None
symbol: str | None = None
entry_type: str | None = None
account_type: str | None = None
protocol: str | None = None
account_subtype: str | None = None
```

Create a private `_base_filters` method that applies common WHERE clauses to a query on JournalEntry+JournalSplit+Account+Wallet joins. The join chain is: `JournalEntry -> JournalSplit (journal_entry_id) -> Account (account_id) -> Wallet (wallet_id)`. Filter by `Wallet.entity_id == entity_id`. Apply date_from/date_to on `JournalEntry.timestamp`. Apply other filters on respective columns.

Implement these 11 methods (all async, return typed dicts/lists):

1. `get_cash_flow_series(granularity: str = "month", **filters)` — Uses `func.date_trunc(granularity, JournalEntry.timestamp)` to group. Looks at ASSET account_type splits only. quantity > 0 = inflow, quantity < 0 = outflow. Returns list of `{period, inflow_usd, inflow_vnd, outflow_usd, outflow_vnd, net_usd, net_vnd}`.

2. `get_kpi_summary(**filters)` — Returns `{total_inflow_usd, total_inflow_vnd, total_outflow_usd, total_outflow_vnd, net_usd, net_vnd, total_entries, total_txs, unique_tokens, unique_protocols}`. Aggregate sums from ASSET splits + count distinct values.

3. `get_top_symbols_by_volume(limit: int = 20, **filters)` — GROUP BY Account.symbol, calculate abs(sum(value_usd)) as volume, sum positive as inflow, sum negative as outflow, count entries. Order by volume DESC.

4. `get_top_protocols_by_volume(limit: int = 20, **filters)` — GROUP BY Account.protocol (WHERE protocol IS NOT NULL), sum abs(value_usd), count, collect distinct entry_types. Order by volume DESC.

5. `get_composition_snapshot(**filters)` — Current balances per account grouped by account_type, subtype, symbol, protocol. Uses sum(JournalSplit.quantity) and sum(value_usd), sum(value_vnd). Only include non-zero balances.

6. `get_activity_heatmap(days: int = 365, **filters)` — GROUP BY date(JournalEntry.timestamp), count entries, sum abs(value_usd). Last N days only.

7. `get_entry_type_breakdown(**filters)` — GROUP BY JournalEntry.entry_type, count + sum abs(value_usd).

8. `get_income_expense_series(granularity: str = "month", **filters)` — Like cash_flow but filters to INCOME + EXPENSE account_types. Groups by period.

9. `get_balance_over_time(granularity: str = "month", symbols: list[str] | None = None, **filters)` — Running sum of splits per symbol per period. Uses window function or subquery with cumulative sum.

10. `get_flow_by_wallet(**filters)` — GROUP BY Wallet.id, include wallet label and chain. Sum inflow/outflow/net from ASSET splits.

11. `get_flow_by_chain(**filters)` — GROUP BY chain (from Wallet or Transaction). Sum inflow/outflow/net from ASSET splits.

Use PostgreSQL `func.date_trunc` for period grouping. Use `func.coalesce` for null safety. All monetary aggregates should use `Decimal`.

Important: The `chain` field is on Wallet (via OnChainWallet polymorphic), so for chain-based queries, join through Wallet and filter `Wallet.chain` if available. For CEX wallets without chain, use the wallet label or "CEX" as chain.
  </action>
  <verify>
Run: `python -c "from cryptotax.db.repos.analytics_repo import AnalyticsRepo; print('OK')"` — imports without error.
Verify the class has all 11 public methods.
  </verify>
  <done>AnalyticsRepo class exists with 11 async query methods, all following the common filter pattern and proper SQLAlchemy joins.</done>
</task>

<task type="auto">
  <name>Task 2: Create TaxAnalyticsRepo + TaxableTransferRecord model + update TaxEngine</name>
  <files>
    src/cryptotax/db/repos/tax_analytics_repo.py
    src/cryptotax/db/models/taxable_transfer.py
    src/cryptotax/accounting/tax_engine.py
  </files>
  <action>
**Step 1: Create TaxableTransferRecord model** in `src/cryptotax/db/models/taxable_transfer.py`:

```python
class TaxableTransferRecord(UUIDPrimaryKey, TimestampMixin, Base):
    __tablename__ = "taxable_transfers"
    entity_id: Mapped[uuid.UUID] = mapped_column(ForeignKey("entities.id"))
    journal_entry_id: Mapped[uuid.UUID] = mapped_column(ForeignKey("journal_entries.id"))
    symbol: Mapped[str] = mapped_column(String(50))
    quantity: Mapped[Decimal] = mapped_column(Numeric(38, 18))
    value_usd: Mapped[Decimal] = mapped_column(Numeric(20, 4))
    value_vnd: Mapped[Decimal] = mapped_column(Numeric(24, 0))
    tax_amount_vnd: Mapped[Decimal] = mapped_column(Numeric(24, 0))
    exemption_reason: Mapped[Optional[str]] = mapped_column(String(50), default=None)
    timestamp: Mapped[datetime]
```

Follow the exact same pattern as ClosedLotRecord/OpenLotRecord (UUIDPrimaryKey, TimestampMixin, Base).

**Step 2: Update TaxEngine._persist_results** to also delete+insert TaxableTransferRecord:

In `_persist_results`, add a `taxable_transfers` parameter. Delete existing `TaxableTransferRecord` for entity, then insert new records. Map from the in-memory TaxableTransfer domain objects:
- `entity_id` from parameter
- `journal_entry_id` — this requires updating `_calculate_transfer_tax` to also capture the `journal_entry_id` from `splits_data` (it's already available as `s["journal_entry_id"]`)
- `exemption_reason` as string (use `.value` if enum, else None)

Update the `calculate` method to pass `taxable_transfers` to `_persist_results`.

**Step 3: Create TaxAnalyticsRepo** in `src/cryptotax/db/repos/tax_analytics_repo.py`:

Accepts AsyncSession. All methods accept `entity_id: UUID` plus optional `date_from`, `date_to`, `symbol` filters.

Implement 8 methods:

1. `get_realized_gains_series(granularity: str = "month", **filters)` — Query ClosedLotRecord, GROUP BY date_trunc(granularity, sell_timestamp). Sum gain_usd where positive (gains), sum where negative (losses), net, count.

2. `get_realized_gains_by_symbol(**filters)` — GROUP BY symbol. Sum gain/loss, count, avg holding_days.

3. `get_holding_period_distribution(**filters)` — Use CASE WHEN on holding_days to bucket: <7d, 7-30d, 30-90d, 90-365d, >365d. Count + sum gain per bucket.

4. `get_winners_losers(limit: int = 10, **filters)` — Top N symbols by gain_usd (winners) and bottom N (losers). Two separate queries or one with ranking.

5. `get_tax_breakdown(granularity: str = "month", **filters)` — Query TaxableTransferRecord, GROUP BY period. Count taxable (no exemption), count exempt, sum value_vnd, sum tax_amount_vnd.

6. `get_tax_by_category(**filters)` — GROUP BY exemption_reason (including NULL for taxable). Count, sum value_vnd, sum tax_amount_vnd.

7. `get_unrealized_pnl(**filters)` — Query OpenLotRecord. Return symbol, qty, cost_basis (qty * cost_per_unit), cost_per_unit. Note: current price lookup is deferred — just return cost basis data for now, frontend can enrich later.

8. `get_cost_basis_summary(**filters)` — GROUP BY symbol on OpenLotRecord. Sum qty, sum (qty * cost_per_unit) as total_cost, avg cost_per_unit weighted.
  </action>
  <verify>
Run: `python -c "from cryptotax.db.models.taxable_transfer import TaxableTransferRecord; print('OK')"` — model imports.
Run: `python -c "from cryptotax.db.repos.tax_analytics_repo import TaxAnalyticsRepo; print('OK')"` — repo imports.
Run: `python -c "from cryptotax.accounting.tax_engine import TaxEngine; print('OK')"` — updated engine imports.
  </verify>
  <done>TaxableTransferRecord model exists, TaxAnalyticsRepo has 8 methods, TaxEngine persists taxable transfers alongside closed/open lots.</done>
</task>

</tasks>

<verification>
- `python -c "from cryptotax.db.repos.analytics_repo import AnalyticsRepo; print(len([m for m in dir(AnalyticsRepo) if not m.startswith('_')]))"` shows 11+ public methods
- `python -c "from cryptotax.db.repos.tax_analytics_repo import TaxAnalyticsRepo; print(len([m for m in dir(TaxAnalyticsRepo) if not m.startswith('_')]))"` shows 8+ public methods
- `python -c "from cryptotax.db.models.taxable_transfer import TaxableTransferRecord; print(TaxableTransferRecord.__tablename__)"` prints "taxable_transfers"
- `ruff check src/cryptotax/db/repos/analytics_repo.py src/cryptotax/db/repos/tax_analytics_repo.py src/cryptotax/db/models/taxable_transfer.py` — no lint errors
</verification>

<success_criteria>
- AnalyticsRepo provides 11 async methods for comprehensive journal/account analytics
- TaxAnalyticsRepo provides 8 async methods for capital gains and tax analytics
- TaxableTransferRecord model is defined with proper columns and foreign keys
- TaxEngine.calculate() persists TaxableTransferRecord alongside closed/open lots
- All code follows existing repo patterns (AsyncSession, proper imports, type hints)
</success_criteria>

<output>
After completion, create `.planning/phases/12-management-dashboard-comprehensive-analytics/12-01-SUMMARY.md`
</output>
